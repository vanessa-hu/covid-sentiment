{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentiment Analysis and Asian Americans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This analysis uses the [GetOldTweets](https://github.com/Mottl/GetOldTweets3) package to retrieve and query tweets with given search parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import GetOldTweets3 as got\n",
    "from datetime import datetime\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "analyzer = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions\n",
    "def clean_text(text):\n",
    "    '''removes links, user tags, and hashtag symbols'''\n",
    "    cleaned = re.sub(r\"(((http|https|ftp)://)|www.)[^\\s]+\", \"\", text)\n",
    "    cleaned = re.sub(r\"((@[\\w]+)|#)\", \"\", cleaned).strip()\n",
    "    return cleaned\n",
    "        \n",
    "def vader_compound(text):\n",
    "    '''returns compound score of VADER sentiment analysis'''\n",
    "    return analyzer.polarity_scores(text)['compound']\n",
    "\n",
    "\n",
    "def covid_keywords(text):\n",
    "    '''returns dict of two keys of form {\"about_covid\": 0 or 1, \"covid_word\": \"NA\" or keyword}'''\n",
    "    \n",
    "    keywords = [(r\"kung[-\\s]*flu\", \"kungflu\"), (r\"chink[-\\s]virus*\", \"chinkvirus\"), (r\"china[-\\s]*virus\",\"china-virus\"),\\\n",
    "                (r\"chinese[-\\s]*virus\", \"chinese-virus\"),(r\"sars[-\\s]*cov[-\\s]*2\",\"sars-cov-2\"),(r\"ncov\",\"ncov\"),\\\n",
    "                (r\"covid[-\\s]*19\",\"covid-19\"),(r\"covid\",\"covid\"),(r\"corona[-\\s]*virus\", \"coronavirus\"),\\\n",
    "                (r\"quarantin\",\"quarantine\"), (r\"corona\", \"corona\"), (r\"pandemic\", \"pandemic\"),\\\n",
    "                (r\"social[-\\s]*distanc\", \"social-distancing\"), (r\"flatten(\\w)*[-\\s]*the[-\\s]*curve\",\"flatten-the-curve\")]\n",
    "    \n",
    "    for key in keywords:\n",
    "        if re.search(key[0], text.lower()):\n",
    "            return {\"about_covid\":1, \"covid_word\": key[1]}\n",
    "            \n",
    "    return {\"about_covid\":0, \"covid_word\": \"NA\"}\n",
    "\n",
    "\n",
    "def china_keywords(text):\n",
    "    '''returns dict of two keys of form {\"about_china\": 0 or 1, \"china_word\": \"NA\" or keyword}'''\n",
    "    \n",
    "    keywords = [(r\"yellow[-\\s]*peril\", \"yellow-peril\"), (r\"kung[-\\s]*flu\", \"kungflu\"), (r\"chink[-\\s]virus*\", \"chinkvirus\"),\\\n",
    "                (r\"chink\", \"chink\"),(r\"china[-\\s]*virus\",\"china-virus\"), (r\"chinese[-\\s]*virus\", \"chinese-virus\"),\\\n",
    "                 (r\"wuhan\", \"wuhan\"), (r\"chinese[-\\s]*america\", \"chinese-america\"), (r\"china[-\\s]*town\", \"chinatown\"),\\\n",
    "                (r\"china\", \"china\"), (r\"chinese\", \"chinese\"), (r\"asian[-\\s]*america\",\"asian-america\"),\\\n",
    "                (r\"asian\", \"asian\"),(r\"asia\",\"asia\")]\n",
    "    \n",
    "    for key in keywords:\n",
    "        if re.search(key[0], text.lower()):\n",
    "            return {\"about_china\":1, \"china_word\": key[1]}\n",
    "            \n",
    "    return {\"about_china\":0, \"china_word\": \"NA\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of dictionaries; each dict stores info about the tweet\n",
    "twt_db = []\n",
    "query = 'lang:en'\n",
    "count = 100\n",
    "feb = [date.strftime(\"%Y-%m-%d\") for date in pd.date_range(start=\"2020-02-01\",end=\"2020-03-01\").to_pydatetime().tolist()]\n",
    "march = [date.strftime(\"%Y-%m-%d\") for date in pd.date_range(start=\"2020-03-01\",end=\"2020-04-01\").to_pydatetime().tolist()]\n",
    "april = [date.strftime(\"%Y-%m-%d\") for date in pd.date_range(start=\"2020-04-01\",end=\"2020-05-01\").to_pydatetime().tolist()]\n",
    "\n",
    "def add_tweets(date_list):\n",
    "    for i in range(len(date_list)-1):\n",
    "        tweetCriteria = got.manager.TweetCriteria().setSince(dates[i]).setUntil(dates[i+1])\\\n",
    "                                            .setMaxTweets(count).setQuerySearch(query)\n",
    "    # list of tweets from this day\n",
    "        tweets = got.manager.TweetManager.getTweets(tweetCriteria)\n",
    "        for twt in tweets:\n",
    "            entry = {}\n",
    "            cleaned = clean_text(twt.text)\n",
    "            date = twt.date.strftime(\"%m-%d-%Y\")\n",
    "            entry.update({\"id\":twt.id, \"tweet\":cleaned,\"date\":date, \"sentiment\":vader_compound(cleaned)})\n",
    "            entry.update(covid_keywords(cleaned))\n",
    "            entry.update(china_keywords(cleaned))\n",
    "            entry[\"link\"] = twt.permalink\n",
    "            twt_db.append(entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_tweets(feb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_tweets(march)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_tweets(april)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save data into txt file for R processing\n",
    "with open(\"all_tweets.txt\", \"w\", encoding='utf-8') as out:\n",
    "    print(\"id\\ttweet\\tdate\\tsentiment\\tabout_covid\\tcovid_word\\tabout_china\\tchina_word\\tlink\", file=out)\n",
    "    for twt in twt_db:\n",
    "        print(str(twt[\"id\"],twt[\"tweet\"],twt[\"date\"],twt[\"sentiment\"],twt[\"about_covid\"], twt[\"covid_word\"],\\\n",
    "              twt[\"about_china\"], twt[\"china_word\"], twt[\"link\"], sep=\"\\t\", end=\"\\n\", file=out)\n",
    "\n",
    "# save list of dicts and the dataframe with pickle\n",
    "with open('tweet_dict.pickle', 'wb') as p_out:\n",
    "    pickle.dump(twt_db, p_out)\n",
    "\n",
    "df = pd.DataFrame(twt_db)\n",
    "df.to_pickle('tweet_df.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(twt_db[1]['id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('tweet_dict.pickle', 'rb') as p_in:\n",
    "    #tweet_dict = pickle.load(p_in)\n",
    "# with open('tweet_df.pickle', 'rb') as p_in:\n",
    "    #tweet_df = pickle.load(p_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setTopTweets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TESTER CODE!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"test.txt\", \"w\", encoding='utf-8') as out:\n",
    "    print(\"what is this utf-8 testing about?\", file=out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = [(r\"kung[-\\s]*flu\", \"kungflu\"), (r\"chink[-\\s]virus*\", \"chinkvirus\"), (r\"china[-\\s]*virus\",\"china-virus\"),\\\n",
    "                (r\"chinese[-\\s]*virus\", \"chinese-virus\"),(r\"sars[-\\s]*cov[-\\s]*2\",\"sars-cov-2\"),\\\n",
    "                (r\"ncov\",\"ncov\"),(r\"covid\",\"covid\"),(r\"corona[-\\s]*virus\", \"coronavirus\"),(r\"quarantin\",\"quarantine\"),\\\n",
    "                 (r\"corona\", \"corona\"), (r\"pandemic\", \"pandemic\"), (r\"social[-\\s]*distanc\", \"social-distancing\"), \\\n",
    "                (r\"flatten(\\w)*[-\\s]*the[-\\s]*curve\",\"flatten-the-curve\")]\n",
    "text = \"flattening the  curve\"\n",
    "for key in keywords:\n",
    "    if re.search(key[0], text.lower()):\n",
    "        print({\"about_covid\":1, \"covid_word\": key[1]})\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = 'lang:en'\n",
    "count = 100\n",
    "# create query object\n",
    "tweetCriteria = got.manager.TweetCriteria().setSince(\"2020-03-01\").setUntil(\"2020-03-02\")\\\n",
    "                                            .setMaxTweets(count).setQuerySearch(query)\n",
    "# list of all tweets\n",
    "tweets = got.manager.TweetManager.getTweets(tweetCriteria)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of dictionaries; each dict stores info about the tweet\n",
    "twt_db = []\n",
    "for twt in tweets:\n",
    "    entry = {}\n",
    "    cleaned = clean_text(twt.text)\n",
    "    date = twt.date.strftime(\"%m-%d-%Y %H:%M:%S\")\n",
    "    entry.update({\"id\":twt.id, \"tweet\":cleaned,\"date\":date,\\\n",
    "                  \"sentiment\":vader_compound(cleaned),\"link\":twt.permalink})\n",
    "    twt_db.append(entry)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for twt in twt_db:\n",
    "    print(twt[\"tweet\"],twt['date'],twt['sentiment'],\"\\n\\n\",sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"tweets.txt\", \"w\") as out:\n",
    "    print(\"id\\ttweet\\tdate\\tsentiment\\tlink\", file=out)\n",
    "    for twt in twt_db:\n",
    "        print(twt[\"id\"],twt[\"tweet\"],twt[\"date\"],twt[\"sentiment\"],twt[\"link\"], sep=\"\\t\", end=\"\\n\", file=out)\n",
    "\n",
    "with open('tweet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testdict = [{\"name\":\"vanessa\",\"school\":\"harvard\",\"age\":19},{\"school\":\"harvard\",\"age\":19}]\n",
    "df = pd.DataFrame(testdict)\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "twt",
   "language": "python",
   "name": "twt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
